# Machine Learning & Generative AI Learning Roadmap üöÄ

This repository documents my **hands-on journey** into Machine Learning (ML), Artificial Intelligence (AI), and the math that powers them ‚Äî with the ultimate goal of building **custom generative AI systems** (text, images, videos) and fine-tuned models for applications like **RAGs (Retrieval-Augmented Generation)** and **Graph RAGs**.

---

## üìå Motivation
Instead of just applying prebuilt libraries, this repo focuses on:
- **Low-level implementations** of algorithms (from scratch using NumPy).  
- **Math foundations** (Linear Algebra, Calculus, Probability & Statistics).  
- **Visualization-first learning** (plotting vectors, regression fits, gradient descent curves).  
- **Step-by-step layering**: mastering fundamentals ‚Üí ML algorithms ‚Üí modern AI applications.

---

## üõ†Ô∏è Roadmap

### 1. **Math Foundations for ML**
- Linear Algebra  
  - Vectors, dot product, projections  
  - Matrix operations, normal equations  
- Calculus  
  - Differentiation (derivatives, partial derivatives)  
  - Gradient, optimization principles  
- Probability & Statistics  
  - Random variables, distributions  
  - Expectation, variance, conditional probability  

**Goal:** Build intuition + connect math concepts with ML applications.

---

### 2. **Core ML Algorithms (From Scratch)**
- ‚úÖ **Linear Regression (Single & Multi-feature)**  
  - Normal Equation (closed-form solution with linear algebra)  
  - Gradient Descent (iterative optimization)  
- ‚è≥ Logistic Regression (classification)  
- ‚è≥ k-Nearest Neighbors  
- ‚è≥ Decision Trees & Random Forests  
- ‚è≥ Support Vector Machines  

**Goal:** Implement step by step, understand underlying math, compare with sklearn.

---

### 3. **Optimization & Training**
- Gradient Descent Variants  
  - Batch, Stochastic, Mini-batch  
- Learning rate scheduling  
- Cost function analysis & convergence visualization  

---

### 4. **Bridging to AI**
- Neural Networks basics  
  - Perceptron ‚Üí Multi-Layer Perceptron  
  - Backpropagation with gradient descent  
- Deep Learning foundations  
  - Activation functions, loss functions  
  - Training dynamics (overfitting, regularization)  

---

### 5. **Applied Generative AI (Final Milestone)**
- Fine-tuning transformer models  
- RAG (Retrieval-Augmented Generation)  
- Graph RAGs (contextual & structured reasoning)  
- Building **custom generative AI apps** (text, image, video).  

---

## üìÇ Repository Structure
